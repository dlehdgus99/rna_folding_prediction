{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":51294,"databundleVersionId":6923401,"sourceType":"competition"},{"sourceId":6991501,"sourceType":"datasetVersion","datasetId":4018542}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric\n!pip install ViennaRNA","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:29.611456Z","iopub.execute_input":"2023-12-02T19:59:29.612123Z","iopub.status.idle":"2023-12-02T19:59:52.480803Z","shell.execute_reply.started":"2023-12-02T19:59:29.612090Z","shell.execute_reply":"2023-12-02T19:59:52.479785Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch_geometric in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.23.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.11.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2023.7.22)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.1.0)\nRequirement already satisfied: ViennaRNA in /opt/conda/lib/python3.10/site-packages (2.6.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import random_split\nfrom torch_geometric.data import Data, Dataset\nfrom torch_geometric.loader import DataLoader\nimport pandas as pd\nfrom pathlib import Path\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nimport polars as pl\nimport re\nfrom tqdm import tqdm\nimport networkx as nx\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:52.482923Z","iopub.execute_input":"2023-12-02T19:59:52.483244Z","iopub.status.idle":"2023-12-02T19:59:52.489234Z","shell.execute_reply.started":"2023-12-02T19:59:52.483216Z","shell.execute_reply":"2023-12-02T19:59:52.488378Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = Path(\"/kaggle/input/stanford-ribonanza-rna-folding/\")\nTRAIN_CSV = DATA_DIR / \"train_data_QUICK_START.csv\"\nTRAIN_PARQUET_FILE = \"train_data.parquet\"\nTEST_CSV = DATA_DIR / \"test_sequences.csv\"\nTEST_PARQUET_FILE = \"test_sequences.parquet\"\nPRED_CSV = \"submission.csv\"\n\nPARQUET_DATA_DIR = Path(\"/kaggle/input/parquet-files/\")\nTRAIN_PARQUET_DIR = PARQUET_DATA_DIR / \"train_data.parquet\"","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:52.490431Z","iopub.execute_input":"2023-12-02T19:59:52.490697Z","iopub.status.idle":"2023-12-02T19:59:52.505790Z","shell.execute_reply.started":"2023-12-02T19:59:52.490674Z","shell.execute_reply":"2023-12-02T19:59:52.504947Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def to_parquet(csv_file, parquet_file):\n    dummy_df = pl.scan_csv(csv_file)\n\n    new_schema = {}\n    for key, value in dummy_df.schema.items():\n        if key.startswith(\"reactivity\"):\n            new_schema[key] = pl.Float32\n        else:\n            new_schema[key] = value\n\n    df = pl.scan_csv(csv_file, schema=new_schema)\n    \n    df.sink_parquet(\n            parquet_file,\n            compression='uncompressed',\n            row_group_size=10,\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:52.506954Z","iopub.execute_input":"2023-12-02T19:59:52.507241Z","iopub.status.idle":"2023-12-02T19:59:52.516421Z","shell.execute_reply.started":"2023-12-02T19:59:52.507212Z","shell.execute_reply":"2023-12-02T19:59:52.515488Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# to_parquet(TRAIN_CSV, TRAIN_PARQUET_FILE)\n# to_parquet(TEST_CSV, TEST_PARQUET_FILE)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:52.519564Z","iopub.execute_input":"2023-12-02T19:59:52.519975Z","iopub.status.idle":"2023-12-02T19:59:52.525439Z","shell.execute_reply.started":"2023-12-02T19:59:52.519946Z","shell.execute_reply":"2023-12-02T19:59:52.524660Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Define adjacency\n\nThere are countless ways you can define adjacency. \nThe function below creates an edge connection array that specifies how the edges are connected. \n\nIn this case, an edge is connected to the neighbouring `n` molecules to each side of it, plus optionally itself. ","metadata":{}},{"cell_type":"code","source":"def nearest_adjacency(sequence_length, n=2, loops=True):\n    base = np.arange(sequence_length)\n    connections = []\n    for i in range(-n, n + 1):\n        if i == 0 and not loops:\n            continue\n        elif i == 0 and loops:\n            stack = np.vstack([base, base])\n            connections.append(stack)\n            continue\n\n        neighbours = base.take(range(i,sequence_length+i), mode='wrap')\n        stack = np.vstack([base, neighbours])\n        \n        if i < 0:\n            connections.append(stack[:, -i:])\n        elif i > 0:\n            connections.append(stack[:, :-i])\n\n    return np.hstack(connections)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:52.526541Z","iopub.execute_input":"2023-12-02T19:59:52.527002Z","iopub.status.idle":"2023-12-02T19:59:52.536339Z","shell.execute_reply.started":"2023-12-02T19:59:52.526969Z","shell.execute_reply":"2023-12-02T19:59:52.535478Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from ViennaRNA import RNA\n\nimport RNA\nimport numpy as np\n\ndef rna_adjacency_matrix(sequence):\n    \"\"\"\n    Creates an adjacency matrix for an RNA sequence based on its predicted secondary structure.\n    \n    Parameters:\n    sequence (str): The RNA sequence.\n    \n    Returns:\n    numpy.ndarray: An adjacency matrix representing the base pairs in the RNA structure.\n    \"\"\"\n    # Predicting the secondary structure\n    ss, _ = RNA.fold(sequence)\n\n    sequence_length = len(sequence)\n    matrix = np.zeros((sequence_length, sequence_length), dtype=int)\n\n    # Stack to hold the indices of open brackets\n    stack = []\n\n    for i, char in enumerate(ss):\n        if char == '(':\n            stack.append(i)\n        elif char == ')':\n            j = stack.pop()\n            matrix[i][j] = 1\n            matrix[j][i] = 1\n\n    return matrix\n\ndef get_rna_structure_edges(sequence):\n    # Predict secondary structure\n    ss, _ = RNA.fold(sequence)\n    edges = []\n    stack = []\n    for i, char in enumerate(ss):\n        if char == '(':\n            stack.append(i)\n        elif char == ')':\n            j = stack.pop()\n            edges.append([i, j])\n    return np.array(edges).T\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:52.537311Z","iopub.execute_input":"2023-12-02T19:59:52.537566Z","iopub.status.idle":"2023-12-02T19:59:52.547547Z","shell.execute_reply.started":"2023-12-02T19:59:52.537543Z","shell.execute_reply":"2023-12-02T19:59:52.546652Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"EDGE_DISTANCE = 4","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:52.548752Z","iopub.execute_input":"2023-12-02T19:59:52.549088Z","iopub.status.idle":"2023-12-02T19:59:52.559399Z","shell.execute_reply.started":"2023-12-02T19:59:52.549063Z","shell.execute_reply":"2023-12-02T19:59:52.558614Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Defining the dataloader. \n\nThe below defines a simple dataloader that parses a parquet file into node embeddings (for now just the one hot encoded bases A, G, U and C), the adjacency (using the function above), and the targets (the reactivity scores). ","metadata":{}},{"cell_type":"code","source":"class SimpleGraphDataset(Dataset):\n    def __init__(self, edge_distance=5, root=None, transform=None, pre_transform=None, pre_filter=None):\n        super().__init__(root, transform, pre_transform, pre_filter)\n        # Set edge distance\n        self.edge_distance = edge_distance\n        \n        \n        # Initialize one hot encoder\n        self.node_encoder = OneHotEncoder(sparse_output=False, max_categories=5)\n        # For one-hot encoder to possible values\n        self.node_encoder.fit(np.array(['A', 'G', 'U', 'C']).reshape(-1, 1))\n        \n        # Load dataframe\n        self.df = pl.read_parquet(TRAIN_PARQUET_DIR)\n        num_rows = int(len(self.df) * 0.1)\n        self.df = self.df[:num_rows]\n\n        # Filter dataframe\n        self.df = self.df.filter(pl.col('experiment_type') == '2A3_MaP')\n        if \"SN_filter\" in self.df.columns:\n            self.df = self.df.filter(pl.col(\"SN_filter\") == 1.0)\n        \n        # Get reactivity columns names\n        reactivity_match = re.compile('(reactivity_[0-9])')\n        reactivity_names = [col for col in self.df.columns if reactivity_match.match(col)]\n        self.reactivity_df = self.df.select(reactivity_names) \n\n        self.sequence_df = self.df.select(\"sequence\")\n        \n        \n    def calculate_additional_feature(self, sequence):\n        return\n    \n    \n    def calculate_centrality(self, edge_index):\n        # Convert edge index to a NetworkX graph to compute centrality\n        G = nx.Graph()\n        # Edge index is assumed to be a 2xN array where each column is an edge\n        G.add_edges_from(edge_index.T.tolist())\n        # Compute degree centrality (returns a dictionary)\n        centrality = nx.degree_centrality(G)\n        # Convert centrality values to a list in the order of nodes\n        centrality_values = [centrality[node] for node in range(len(G))]\n        return np.array(centrality_values).reshape(-1, 1)\n\n    def parse_row(self, idx):\n        # Read row at idx\n        sequence_row = self.sequence_df.row(idx)  \n        reactivity_row = self.reactivity_df.row(idx)\n        \n        # Get sequence string and convert to array\n        sequence = np.array(list(sequence_row[0])).reshape(-1, 1)\n        # Encode sequence array\n        encoded_sequence = self.node_encoder.transform(sequence)\n        # Get sequence length\n        sequence_length = len(sequence)\n        \n        \n        # Get edge index from nearest adjacency\n        nearest_edges = nearest_adjacency(sequence_length, n=self.edge_distance, loops=False)\n\n        # Get edge index from RNA secondary structure\n        structure_edges = get_rna_structure_edges(sequence_row[0])\n\n        # Combine both sets of edges\n        combined_edges = np.hstack([nearest_edges, structure_edges])\n\n        # Convert to torch tensor\n        edge_index = torch.tensor(combined_edges, dtype=torch.long)\n\n        # Get edge index \n#         edges_np = nearest_adjacency(sequence_length, n=self.edge_distance, loops=False)\n#         # Convert to torch tensor\n#         edge_index = torch.tensor(edges_np, dtype=torch.long)\n\n        \n        # Get reactivity targets for nodes\n        reactivity = np.array(reactivity_row, dtype=np.float32)[0:sequence_length]\n     \n        # Create valid masks for nodes\n        valid_mask = np.argwhere(~np.isnan(reactivity)).reshape(-1)\n        torch_valid_mask = torch.tensor(valid_mask, dtype=torch.long)\n\n        # Replace nan values for reactivity with 0. \n        # Not actually super important as they get masked\n        reactivity = np.nan_to_num(reactivity, copy=False, nan=0.0)\n\n\n        centrality_feature = self.calculate_centrality(edge_index)\n        combined_features = np.concatenate([encoded_sequence, centrality_feature], axis=1)\n        # Define node features as one-hot encoded sequence\n        node_features = torch.Tensor(combined_features)\n\n\n        # Targets \n        targets = torch.Tensor(reactivity)\n\n        data = Data(x=node_features, edge_index=edge_index, y=targets, valid_mask=torch_valid_mask)\n\n        return data\n\n    def len(self):\n        return len(self.df)\n\n    def get(self, idx):\n        data = self.parse_row(idx)\n        return data","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:52.560808Z","iopub.execute_input":"2023-12-02T19:59:52.561140Z","iopub.status.idle":"2023-12-02T19:59:52.579315Z","shell.execute_reply.started":"2023-12-02T19:59:52.561116Z","shell.execute_reply":"2023-12-02T19:59:52.578475Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Data handling\n\nDefine the train, validation, and test datasets, and load them with dataloaders. ","metadata":{}},{"cell_type":"code","source":"full_train_dataset = SimpleGraphDataset(edge_distance=EDGE_DISTANCE)\ngenerator1 = torch.Generator().manual_seed(42)\ntrain_dataset, val_dataset = random_split(full_train_dataset, [0.7, 0.3], generator1)\nval_dataset, test_dataset = random_split(val_dataset, [0.7, 0.3], generator1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:52.580453Z","iopub.execute_input":"2023-12-02T19:59:52.580731Z","iopub.status.idle":"2023-12-02T19:59:54.207017Z","shell.execute_reply.started":"2023-12-02T19:59:52.580706Z","shell.execute_reply":"2023-12-02T19:59:54.206181Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\nval_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=2)\ntest_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:54.208159Z","iopub.execute_input":"2023-12-02T19:59:54.208451Z","iopub.status.idle":"2023-12-02T19:59:54.214274Z","shell.execute_reply.started":"2023-12-02T19:59:54.208426Z","shell.execute_reply":"2023-12-02T19:59:54.213312Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Loss and metrics\n\nDefine the loss function and the MSE, and define the MAE as a loss. \n\nThe target values are clipped to `(0, 1)` as the competition metric is. ","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef loss_fn(output, target):\n    clipped_target = torch.clip(target, min=0, max=1)\n    mses = F.mse_loss(output, clipped_target, reduction='mean')\n    return mses\n\ndef mae_fn(output, target):\n    clipped_target = torch.clip(target, min=0, max=1)\n    maes = F.l1_loss(output, clipped_target, reduction='mean')\n    return maes","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:54.215586Z","iopub.execute_input":"2023-12-02T19:59:54.215945Z","iopub.status.idle":"2023-12-02T19:59:54.225649Z","shell.execute_reply.started":"2023-12-02T19:59:54.215912Z","shell.execute_reply":"2023-12-02T19:59:54.224762Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Define the model\n\nBelow we define as simple EdgeCNN from PyG. \nAs a start, we give it 128 hidden channels, and 4 layers. ","metadata":{}},{"cell_type":"code","source":"from torch_geometric.nn.models import EdgeCNN\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = EdgeCNN(in_channels=full_train_dataset.num_features, hidden_channels=128,\n                num_layers=4, out_channels=1,dropout=0.5).to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:54.226726Z","iopub.execute_input":"2023-12-02T19:59:54.227043Z","iopub.status.idle":"2023-12-02T19:59:54.275221Z","shell.execute_reply.started":"2023-12-02T19:59:54.227020Z","shell.execute_reply":"2023-12-02T19:59:54.274252Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training \n","metadata":{}},{"cell_type":"code","source":"n_epochs = 10\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=5e-4)\n\nfor epoch in range(n_epochs):\n    train_losses = []\n    train_maes = []\n    model.train()\n    for batch in (pbar := tqdm(train_dataloader, position=0, leave=True)):\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index)\n        out = torch.squeeze(out)\n        loss = loss_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n        mae = mae_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n        loss.backward()\n        train_losses.append(loss.detach().cpu().numpy())\n        train_maes.append(mae.detach().cpu().numpy())\n        optimizer.step()\n        pbar.set_description(f\"Train loss {loss.detach().cpu().numpy():.4f}\")       \n\n    print(f\"Epoch {epoch} train loss: \", np.mean(train_losses))    \n    print(f\"Epoch {epoch} train mae: \", np.mean(train_maes))    \n    \n    val_losses = []\n    val_maes = []\n    model.eval()\n    for batch in (pbar := tqdm(val_dataloader, position=0, leave=True)):\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index)\n        out = torch.squeeze(out)\n        loss = loss_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n        mae = mae_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n        val_losses.append(loss.detach().cpu().numpy())\n        val_maes.append(mae.detach().cpu().numpy())\n        pbar.set_description(f\"Validation loss {loss.detach().cpu().numpy():.4f}\")\n        \n    print(f\"Epoch {epoch} val loss: \", np.mean(val_losses))\n    print(f\"Epoch {epoch} val mae: \", np.mean(val_maes))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:59:54.278525Z","iopub.execute_input":"2023-12-02T19:59:54.278805Z","iopub.status.idle":"2023-12-02T20:35:23.291279Z","shell.execute_reply.started":"2023-12-02T19:59:54.278780Z","shell.execute_reply":"2023-12-02T20:35:23.290101Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"  0%|          | 0/46 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(message)\nTrain loss 0.0983: 100%|██████████| 46/46 [02:44<00:00,  3.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0 train loss:  0.12950659\nEpoch 0 train mae:  0.32078654\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1329: 100%|██████████| 14/14 [00:48<00:00,  3.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0 val loss:  0.110138215\nEpoch 0 val mae:  0.28558743\n","output_type":"stream"},{"name":"stderr","text":"Train loss 0.1449: 100%|██████████| 46/46 [02:44<00:00,  3.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 train loss:  0.11688521\nEpoch 1 train mae:  0.28868455\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1299: 100%|██████████| 14/14 [00:49<00:00,  3.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 val loss:  0.10511852\nEpoch 1 val mae:  0.27563912\n","output_type":"stream"},{"name":"stderr","text":"Train loss 0.0859: 100%|██████████| 46/46 [02:43<00:00,  3.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 train loss:  0.11312051\nEpoch 2 train mae:  0.28394493\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1294: 100%|██████████| 14/14 [00:49<00:00,  3.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 val loss:  0.10444168\nEpoch 2 val mae:  0.27286857\n","output_type":"stream"},{"name":"stderr","text":"Train loss 0.1017: 100%|██████████| 46/46 [02:43<00:00,  3.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 train loss:  0.115035266\nEpoch 3 train mae:  0.2865838\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1299: 100%|██████████| 14/14 [00:49<00:00,  3.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 val loss:  0.103378706\nEpoch 3 val mae:  0.26628202\n","output_type":"stream"},{"name":"stderr","text":"Train loss 0.1146: 100%|██████████| 46/46 [02:44<00:00,  3.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 train loss:  0.11279132\nEpoch 4 train mae:  0.28228074\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1292: 100%|██████████| 14/14 [00:49<00:00,  3.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 val loss:  0.103542194\nEpoch 4 val mae:  0.26828864\n","output_type":"stream"},{"name":"stderr","text":"Train loss 0.1314: 100%|██████████| 46/46 [02:43<00:00,  3.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 train loss:  0.11432973\nEpoch 5 train mae:  0.28485757\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1290: 100%|██████████| 14/14 [00:48<00:00,  3.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 val loss:  0.10361055\nEpoch 5 val mae:  0.26808384\n","output_type":"stream"},{"name":"stderr","text":"Train loss 0.1204: 100%|██████████| 46/46 [02:43<00:00,  3.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 train loss:  0.115758024\nEpoch 6 train mae:  0.28435472\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1294: 100%|██████████| 14/14 [00:49<00:00,  3.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 val loss:  0.10378784\nEpoch 6 val mae:  0.2696515\n","output_type":"stream"},{"name":"stderr","text":"Train loss 0.1264: 100%|██████████| 46/46 [02:43<00:00,  3.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 train loss:  0.11210272\nEpoch 7 train mae:  0.2797796\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1296: 100%|██████████| 14/14 [00:49<00:00,  3.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 val loss:  0.10456257\nEpoch 7 val mae:  0.27223137\n","output_type":"stream"},{"name":"stderr","text":"Train loss 0.1150: 100%|██████████| 46/46 [02:43<00:00,  3.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 train loss:  0.11202128\nEpoch 8 train mae:  0.2819653\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1299: 100%|██████████| 14/14 [00:49<00:00,  3.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 val loss:  0.103532806\nEpoch 8 val mae:  0.26751897\n","output_type":"stream"},{"name":"stderr","text":"Train loss 0.0954: 100%|██████████| 46/46 [02:43<00:00,  3.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 train loss:  0.11595975\nEpoch 9 train mae:  0.28522447\n","output_type":"stream"},{"name":"stderr","text":"Validation loss 0.1301: 100%|██████████| 14/14 [00:49<00:00,  3.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 9 val loss:  0.10503002\nEpoch 9 val mae:  0.27549264\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T20:35:23.293272Z","iopub.execute_input":"2023-12-02T20:35:23.293638Z","iopub.status.idle":"2023-12-02T20:35:23.357046Z","shell.execute_reply.started":"2023-12-02T20:35:23.293604Z","shell.execute_reply":"2023-12-02T20:35:23.356047Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Check model performance","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.eval().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T20:35:23.358244Z","iopub.execute_input":"2023-12-02T20:35:23.358518Z","iopub.status.idle":"2023-12-02T20:35:23.372619Z","shell.execute_reply.started":"2023-12-02T20:35:23.358495Z","shell.execute_reply":"2023-12-02T20:35:23.371809Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"EdgeCNN(5, 1, num_layers=4)"},"metadata":{}}]},{"cell_type":"code","source":"test_maes = []\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():  # Disable gradient computation\n    for batch in tqdm(test_dataloader, position=0, leave=True):\n        batch = batch.to(device)  # Move the batch to the appropriate device\n        out = model(batch.x, batch.edge_index)  # Forward pass\n        out = torch.squeeze(out)\n        mae = mae_fn(out[batch.valid_mask], batch.y[batch.valid_mask])  # Calculate MAE\n        test_maes.append(mae.detach().cpu().numpy())  # Store MAE\n\n# Calculate and print average loss and MAE for the test dataset\nprint(f\"Test MAE: {np.mean(test_maes):.4f}\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T20:35:23.373774Z","iopub.execute_input":"2023-12-02T20:35:23.374162Z","iopub.status.idle":"2023-12-02T20:35:45.354013Z","shell.execute_reply.started":"2023-12-02T20:35:23.374136Z","shell.execute_reply":"2023-12-02T20:35:45.352908Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"100%|██████████| 12/12 [00:21<00:00,  1.83s/it]","output_type":"stream"},{"name":"stdout","text":"Test MAE: 0.2861\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}